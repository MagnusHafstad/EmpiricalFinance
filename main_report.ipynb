{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Background\n",
    "\n",
    "Numerous empirical studies have examined the impact of major global crises on stock market volatility. Analyses of S&P 500 data during the 2008 global financial crisis show that this period was marked by historically high levels of volatility, particularly among financial sector stocks. However, the market did not expect volatility to remain elevated for long, and it did not (Schwert, 2011). Similarly, studies conducted during the COVID-19 pandemic documented unprecedented increases in conditional volatility. The effects were not symmetrical. For instance, the negative impact of deaths was more pronounced than the positive effect of recoveries (Basuony et al., 2022). These findings highlight the relevance of analyzing volatility persistence.\n",
    "\n",
    "Financial volatility, defined as the conditional standard deviation of an underlying asset’s returns over time (Tsay, 2010, p. 97), has long been a central topic in economic and financial research. Traditional time series models such as ARMA (Autoregressive Moving Average) and ARIMA, popularized by Box and Jenkins (1970), are frequently used for modeling and forecasting financial data. These models effectively capture linear relationships in the mean of a time series but assume homoskedasticity (the variance of the error term is constant). However, their assumption of homoskedasticity limits their effectiveness in accurately modeling volatility clustering, a common feature in financial markets. As a result, this limitation motivated the development of models specifically designed to capture time-varying volatility.\n",
    "\n",
    "Recognizing the limitations of homoskedasticity assumptions, Engle (1982) introduced the Autoregressive Conditional Heteroskedasticity (ARCH) model. This innovation allowed for the variance of a time series to change over time by using past error terms to predict future variability. Engle’s work marked a significant turning point in financial econometrics by establishing the importance of capturing time-varying volatility in financial data.\n",
    "\n",
    "Bollerslev (1986) built upon Engle’s ideas by developing the GARCH model, which generalizes the ARCH model by including an autoregressive structure in the variance. This extension makes it possible to capture longer-term effects and more complex patterns in volatility and has proven to be a more robust approach for modeling financial time series. The GARCH model’s ability to handle time-dependent changes in variance has made it a standard tool in empirical financial analysis, especially in risk management and portfolio construction.\n",
    "\n",
    "An important aspect of the research is understanding how global economic events impact market volatility. Structural breaks are sudden changes in the underlying behavior of financial data that often occur during events like financial crises or pandemics. Methods such as the Chow Test are used to test the effects of breaks on specific dates, allowing researchers to distinguish between different volatility regimes. However, if breaks are not known in advance, the Quandt likelihood ratio (QLR) test will be more suitable (Brooks, 2019, p. 309). Identifying structural breaks is essential to distinguish between different volatility regimes and improve model accuracy.\n",
    "\n",
    "Moreover, assessing the stationarity of the time series is critical. A time-series is considered strictly stationary if its distribution of values remains constant over time (Brooks, 2019, p. 332). To test the hypothesis that a series is stationary, various statistical tests have been developed, with the Dickey-Fuller test being one of the most widely used methods. This test examines the presence of a unit root, which indicates non-stationarity. However, this standard unit-root test does not perform well if there are several structural breaks in the series (Brooks, 2019, p. 453). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Method\n",
    "\n",
    "The general procedure we follow consist of building GARCH models and testing their relative differences. However, we start by performing exploratory analysis to investigate the presence of certian relationships in the log return series, with the aim of gaining an understanding of its behavior.\n",
    "\n",
    "Below follow the procedure we have used, along with the code and explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import f\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from arch import arch_model\n",
    "from scipy.stats import chi2\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we extract the closing prices of the GSPC ticker symbol, which corresponds to the S&P 500 index. Then we convert the closing-price series into a log return series. This log return series is our foundation for all further work. We also define the events and their corresponding time periods. The event_windows variable holds the events that we use for our analysis. The \"break date\" is given as the iddle date for each of the events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot_com_bubble → 1997-01-01 to 2003-01-01 (event at 2000-03-10)\n",
      "  Observations: 1509\n",
      "\n",
      "financial_crisis → 2006-01-01 to 2011-01-01 (event at 2008-09-15)\n",
      "  Observations: 1259\n",
      "\n",
      "flash_crash → 2008-05-06 to 2012-05-06 (event at 2010-05-06)\n",
      "  Observations: 1009\n",
      "\n",
      "covid_crash → 2018-03-11 to 2022-03-11 (event at 2020-03-11)\n",
      "  Observations: 1009\n",
      "\n",
      "russia_invasion → 2020-02-24 to 2024-02-24 (event at 2022-02-24)\n",
      "  Observations: 1008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = yf.Ticker(\"^GSPC\").history(period=\"max\")\n",
    "df['daily_log_returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "df = df.dropna()\n",
    "\n",
    "log_returns = df['daily_log_returns']\n",
    "\n",
    "\n",
    "event_windows = [\n",
    "    (\"dot_com_bubble\",   \"1997-01-01\", \"2000-03-10\", \"2003-01-01\"),\n",
    "    (\"financial_crisis\", \"2006-01-01\", \"2008-09-15\", \"2011-01-01\"),\n",
    "    (\"flash_crash\",      \"2008-05-06\", \"2010-05-06\", \"2012-05-06\"),\n",
    "    (\"covid_crash\",      \"2018-03-11\", \"2020-03-11\", \"2022-03-11\"),\n",
    "    (\"russia_invasion\",  \"2020-02-24\", \"2022-02-24\", \"2024-02-24\"),\n",
    "]\n",
    "\n",
    "structured_periods = []\n",
    "for name, start, event_date, end in event_windows:\n",
    "    period_data = log_returns.loc[start:end]\n",
    "    structured_periods.append({\n",
    "        \"event\": name,\n",
    "        \"start\": start,\n",
    "        \"event_date\": event_date,\n",
    "        \"end\": end,\n",
    "        \"returns\": period_data\n",
    "    })\n",
    "\n",
    "for p in structured_periods:\n",
    "    print(f\"{p['event']} → {p['start']} to {p['end']} (event at {p['event_date']})\")\n",
    "    print(f\"  Observations: {len(p['returns'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity testing\n",
    "\n",
    "To validate the usage of time series models like ARMA, we explore whether the return series is stationairy or not. For this, we use the Augmented Dickey Fuller test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -22.505443248370327\n",
      "p-value: 0.0\n",
      "Used lags: 48\n",
      "Number of observations: 24377\n",
      "Critical values:\n",
      "   1%: -3.4306182852169496\n",
      "   5%: -2.8616585738095623\n",
      "   10%: -2.566833113395068\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(log_returns)  \n",
    "\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])\n",
    "print(\"Used lags:\", result[2])\n",
    "print(\"Number of observations:\", result[3])\n",
    "print(\"Critical values:\")\n",
    "for key, value in result[4].items():\n",
    "    print(f\"   {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value indicates that the null hypothesis can be rejected. Since the null hypothesis is that the return series has a unit root, we reject this, and the outcome is that the return series can be regarded as stationariy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall level of variance\n",
    "\n",
    "To obtain an idea of the overall changes in variance in regard to the specific events, we performed an F-test. The F-test compared the sample variance before an event, with the sample variance after the event. This was done on all the events and corresponding time intervals. As indicated by the test results, the F-test suggests that there is significant change in the variance of each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== F-test variance results ===\n",
      "              event       start  event_date         end  var_before  \\\n",
      "0    dot_com_bubble  1997-01-01  2000-03-10  2003-01-01    0.000146   \n",
      "1  financial_crisis  2006-01-01  2008-09-15  2011-01-01    0.000101   \n",
      "2       flash_crash  2008-05-06  2010-05-06  2012-05-06    0.000464   \n",
      "3       covid_crash  2018-03-11  2020-03-11  2022-03-11    0.000117   \n",
      "4   russia_invasion  2020-02-24  2022-02-24  2024-02-24    0.000280   \n",
      "\n",
      "   var_after    F_stat       p_value  \n",
      "0   0.000215  0.677315  9.206945e-08  \n",
      "1   0.000419  0.241116  9.501963e-68  \n",
      "2   0.000166  2.797905  2.220446e-16  \n",
      "3   0.000249  0.468542  4.473343e-17  \n",
      "4   0.000143  1.959486  8.215650e-14  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f_test_variance(x1, x2):\n",
    "    s1_sq = np.var(x1, ddof=1)\n",
    "    s2_sq = np.var(x2, ddof=1)\n",
    "    F_stat = s1_sq / s2_sq\n",
    "    df1 = len(x1) - 1\n",
    "    df2 = len(x2) - 1\n",
    "    # Two-sided p-value\n",
    "    p_value = 2 * min(f.cdf(F_stat, df1, df2), 1 - f.cdf(F_stat, df1, df2))\n",
    "    return s1_sq, s2_sq, F_stat, p_value\n",
    "\n",
    "f_test_results = []\n",
    "for name, start, event_date, end in event_windows:\n",
    "    data_full = log_returns.loc[start:end]\n",
    "\n",
    "    before = data_full.loc[start:event_date].iloc[:-1]  \n",
    "    after  = data_full.loc[event_date:]\n",
    "\n",
    "    s1, s2, F_stat, p_val = f_test_variance(before, after)\n",
    "    f_test_results.append({\n",
    "        \"event\": name,\n",
    "        \"start\": start,\n",
    "        \"event_date\": event_date,\n",
    "        \"end\": end,\n",
    "        \"var_before\": s1,\n",
    "        \"var_after\": s2,\n",
    "        \"F_stat\": F_stat,\n",
    "        \"p_value\": p_val\n",
    "    })\n",
    "\n",
    "f_test_df = pd.DataFrame(f_test_results)\n",
    "print(\"=== F-test variance results ===\")\n",
    "print(f_test_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA, ARCH-LM (Engle)\n",
    "\n",
    "Given that the return series is stationariy, we want to build GARCH models to investigate the conditional heteroskedasticity. To do this, we attempt to remove dependencies from the residuals. For this, we use an ARMA model to fit the data, and compute residuals. Specifically, we use the ARIMA-python package, but with 0 differencing, so that the behaivor is that of the regular ARMA. There is no need to perform differencing, as we already have a stationary asset log return series. \n",
    "\n",
    "The models are fitted by attemping to fit orders of (0,1,2,3). This is repeated for all the events (events are defined above). \n",
    "\n",
    "After fitting the models, we investigate the presence of ARCH effects. ARCH effects refer to how the residuals can be correlated to residuals in earlier lags in regards to magnitude (squared etc). To investigate the ARCH effects for the events we have defined, we perform an ARCH-LM test, also known as Engle's ARCH test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ARMA best orders & ARCH-LM test ===\n",
      "              event  p  q     LM_stat       p_value ARCH_effects\n",
      "0    dot_com_bubble  0  0  106.888422  2.259278e-18          Yes\n",
      "1  financial_crisis  3  0  398.177955  2.298807e-79          Yes\n",
      "2       flash_crash  2  0  293.699580  3.335327e-57          Yes\n",
      "3       covid_crash  3  2  334.970642  6.140149e-66          Yes\n",
      "4   russia_invasion  0  3  305.627744  1.003831e-59          Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_values = range(4)\n",
    "q_values = range(4)\n",
    "\n",
    "arch_lm_results = []\n",
    "for name, start, event_date, end in event_windows:\n",
    "    data = log_returns.loc[start:end]\n",
    "\n",
    "    best_aic = np.inf\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "\n",
    "    for p, q in itertools.product(p_values, q_values):\n",
    "        try:\n",
    "            model = ARIMA(data, order=(p, 0, q)).fit()\n",
    "            if model.aic < best_aic:\n",
    "                best_aic = model.aic\n",
    "                best_order = (p, q)\n",
    "                best_model = model\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if best_model is None:\n",
    "        arch_lm_results.append({\n",
    "            \"event\": name,\n",
    "            \"p\": None,\n",
    "            \"q\": None,\n",
    "            \"LM_stat\": None,\n",
    "            \"p_value\": None,\n",
    "            \"ARCH_effects\": \"Model fitting failed\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    #ARCH-LM test/Engle's test\n",
    "    residuals = best_model.resid\n",
    "    lm_test = het_arch(residuals)\n",
    "    LM_stat = lm_test[0]\n",
    "    LM_pvalue = lm_test[1]\n",
    "\n",
    "    arch_lm_results.append({\n",
    "        \"event\": name,\n",
    "        \"p\": best_order[0],\n",
    "        \"q\": best_order[1],\n",
    "        \"LM_stat\": LM_stat,\n",
    "        \"p_value\": LM_pvalue,\n",
    "        \"ARCH_effects\": \"Yes\" if LM_pvalue < 0.05 else \"No\"\n",
    "    })\n",
    "\n",
    "arch_lm_df = pd.DataFrame(arch_lm_results)\n",
    "print(\"=== ARMA best orders & ARCH-LM test ===\")\n",
    "print(arch_lm_df)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chow test for testing of structural breaks\n",
    "\n",
    "\n",
    "To assess the presence of structural breaks in the dynamics of daily returns surrounding key financial events, we applied a **Chow F-test** using the ARMA models identified during the building of **GARCH** models. We then estimated the models separately on three datasets: the full event window, the pre-event period, and the post-event period. This was done on all periods.\n",
    "\n",
    "The Chow test evaluates whether fitting separate models to the pre- and post-event samples results in a statistically significant improvement in fit compared to a single model applied to the full period. The test statistic is computed as:\n",
    "\n",
    "$$\n",
    "F = \\frac{ \\left( SSR_{\\text{full}} - (SSR_{\\text{before}} + SSR_{\\text{after}}) \\right) (n_1 + n_2) }{ (SSR_{\\text{before}} + SSR_{\\text{after}}) \\cdot k }\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- $ SSR_{\\text{full}}, SSR_{\\text{before}}, SSR_{\\text{after}} $ are the sum of squared residuals from the full, pre-, and post-event models, respectively.\n",
    "- $ k $ is the number of estimated parameters in the ARMA model (including the intercept).\n",
    "- $ n_1 $ and $ n_2 $ are the number of observations in the pre- and post-event samples.\n",
    "\n",
    "The **null hypothesis** is that the same ARMA process governs both sub-periods.  \n",
    "A **significant F-statistic** indicates that the model parameters differ before and after the event, suggesting a structural break in the return dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dot_com_bubble] SSR full: 0.2696, before: 0.1172, after: 0.1517\n",
      "Lengths → full: 1509, before: 805, after: 705\n",
      "\n",
      "[financial_crisis] SSR full: 0.3013, before: 0.0692, after: 0.2337\n",
      "Lengths → full: 1259, before: 680, after: 580\n",
      "\n",
      "[flash_crash] SSR full: 0.3095, before: 0.2250, after: 0.0827\n",
      "Lengths → full: 1009, before: 505, after: 505\n",
      "\n",
      "[covid_crash] SSR full: 0.1584, before: 0.0591, after: 0.1129\n",
      "Lengths → full: 1009, before: 504, after: 506\n",
      "\n",
      "[russia_invasion] SSR full: 0.2021, before: 0.1237, after: 0.0715\n",
      "Lengths → full: 1008, before: 507, after: 502\n",
      "\n",
      "              event model_order    F_stat       p_value significant\n",
      "0    dot_com_bubble      (0, 0)  4.281926  3.868969e-02         Yes\n",
      "1  financial_crisis      (3, 0)  0.000000  1.000000e+00          No\n",
      "2       flash_crash      (2, 0)  2.000858  1.122111e-01          No\n",
      "3       covid_crash      (3, 2)  0.000000  1.000000e+00          No\n",
      "4   russia_invasion      (0, 3)  8.839006  5.153350e-07         Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def perform_chow_test_from_known_order(full_data, before_data, after_data, p, q):\n",
    "    try:\n",
    "        model_full = ARIMA(full_data, order=(p, 0, q)).fit()\n",
    "        model_before = ARIMA(before_data, order=(p, 0, q)).fit()\n",
    "        model_after = ARIMA(after_data, order=(p, 0, q)).fit()\n",
    "        \n",
    "        SSR_p = np.sum(model_full.resid ** 2)\n",
    "        SSR_1 = np.sum(model_before.resid ** 2)\n",
    "        SSR_2 = np.sum(model_after.resid ** 2)\n",
    "        print(f\"[{event}] SSR full: {SSR_p:.4f}, before: {SSR_1:.4f}, after: {SSR_2:.4f}\")\n",
    "        print(f\"Lengths → full: {len(full_data)}, before: {len(before_data)}, after: {len(after_data)}\\n\")\n",
    "\n",
    "\n",
    "        n1 = len(before_data)\n",
    "        n2 = len(after_data)\n",
    "        k = p + q + 1  # intercept + AR + MA\n",
    "\n",
    "        numerator = max(0, (SSR_p - (SSR_1 + SSR_2))) / k\n",
    "        denominator = (SSR_1 + SSR_2) / (n1 + n2 - 2 * k)\n",
    "        F_stat = numerator / denominator\n",
    "        p_value = 1 - f.cdf(F_stat, k, (n1 + n2 - 2 * k))\n",
    "\n",
    "        return {\n",
    "            \"F_stat\": F_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"significant\": \"Yes\" if p_value < 0.05 else \"No\",\n",
    "            \"model_order\": (p, q)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "chow_results = []\n",
    "\n",
    "for period in structured_periods:\n",
    "    event = period[\"event\"]\n",
    "    full_data = period[\"returns\"]\n",
    "    before_data = full_data.loc[:period[\"event_date\"]]\n",
    "    after_data = full_data.loc[period[\"event_date\"]:]\n",
    "\n",
    "    arma_row = arch_lm_df[arch_lm_df['event'] == event].iloc[0]\n",
    "    p, q = int(arma_row['p']), int(arma_row['q'])\n",
    "\n",
    "    result = perform_chow_test_from_known_order(full_data, before_data, after_data, p, q)\n",
    "    result[\"event\"] = event\n",
    "    chow_results.append(result)\n",
    "\n",
    "chow_df = pd.DataFrame(chow_results)\n",
    "print(chow_df[[\"event\", \"model_order\", \"F_stat\", \"p_value\", \"significant\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GARCH \n",
    "\n",
    "We have established the presence of ARCH effects, and as a result there is benefit in fitting GARCH models. To build the GARCH models, we use the ARMA(p,q)/ARIMA(p,0,q) models identified earlier as the \"mean equation\". \n",
    "\n",
    "To explore the structural volatility relationship changes, we build GARCH models. In order to remove dependencies from the residuals, we use ARMA models as the mean equation. For each event window, we identified the optimal ARMA(p, q) model by minimizing the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) across combinations of p and q in the range [0, 3]. We then tested for ARCH effects in the residuals using the ARCH-LM test.\n",
    "\n",
    "If ARCH effects were detected (p < 0.05), we fit GARCH(p, q) models (with p, q ∈ [1, 3]) to the ARMA residuals. The optimal GARCH specification was selected based on both AIC and BIC criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GARCH summary results ===\n",
      "              event ARMA(p,q) Best GARCH(p,q) AIC          AIC  \\\n",
      "0    dot_com_bubble    (0, 0)              (2, 3) -8896.810455   \n",
      "1  financial_crisis    (3, 0)              (3, 1) -7677.692660   \n",
      "2       flash_crash    (2, 0)              (3, 3) -5855.022640   \n",
      "3       covid_crash    (3, 2)              (2, 1) -6475.197944   \n",
      "4   russia_invasion    (0, 3)              (1, 2) -6199.471489   \n",
      "\n",
      "  Best GARCH(p,q) BIC          BIC  \n",
      "0              (1, 1) -8871.086035  \n",
      "1              (3, 1) -7652.002295  \n",
      "2              (2, 1) -5828.006177  \n",
      "3              (1, 1) -6458.179392  \n",
      "4              (1, 2) -6179.808595  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/arch/univariate/base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
      "Positive directional derivative for linesearch\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/arch/univariate/base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
      "Positive directional derivative for linesearch\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/arch/univariate/base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
      "Positive directional derivative for linesearch\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "garch_results = []\n",
    "for _, row in arch_lm_df.iterrows():\n",
    "    event = row[\"event\"]\n",
    "    p_val = row[\"p\"]\n",
    "    q_val = row[\"q\"]\n",
    "\n",
    "    # Skip if ARMA order not found\n",
    "    if pd.isnull(p_val) or pd.isnull(q_val):\n",
    "        continue\n",
    "\n",
    "    p_val = int(p_val)\n",
    "    q_val = int(q_val)\n",
    "\n",
    "    (__, start, event_date, end) = next(x for x in event_windows if x[0] == event)\n",
    "    data = log_returns.loc[start:end]\n",
    "\n",
    "    try:\n",
    "        arma_model = ARIMA(data, order=(p_val, 0, q_val)).fit()\n",
    "        residuals = arma_model.resid\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    best_aic = np.inf\n",
    "    best_bic = np.inf\n",
    "    best_aic_model = None\n",
    "    best_bic_model = None\n",
    "    best_aic_order = None\n",
    "    best_bic_order = None\n",
    "\n",
    "    for gp, gq in itertools.product(range(1, 4), range(1, 4)):\n",
    "        try:\n",
    "            garch_mod = arch_model(residuals, vol='Garch', p=gp, q=gq, mean='Zero')\n",
    "            garch_fit = garch_mod.fit(disp=\"off\")\n",
    "\n",
    "            if garch_fit.aic < best_aic:\n",
    "                best_aic = garch_fit.aic\n",
    "                best_aic_order = (gp, gq)\n",
    "                best_aic_model = garch_fit\n",
    "\n",
    "            if garch_fit.bic < best_bic:\n",
    "                best_bic = garch_fit.bic\n",
    "                best_bic_order = (gp, gq)\n",
    "                best_bic_model = garch_fit\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    garch_results.append({\n",
    "        \"event\": event,\n",
    "        \"ARMA(p,q)\": (p_val, q_val),\n",
    "        \"GARCH(p,q) AIC\": best_aic_order,\n",
    "        \"AIC\": best_aic,\n",
    "        \"GARCH(p,q) BIC\": best_bic_order,\n",
    "        \"BIC\": best_bic,\n",
    "        \"model_AIC\": best_aic_model,\n",
    "        \"model_BIC\": best_bic_model\n",
    "    })\n",
    "\n",
    "garch_summary_df = pd.DataFrame([{\n",
    "    \"event\": r[\"event\"],\n",
    "    \"ARMA(p,q)\": r[\"ARMA(p,q)\"],\n",
    "    \"Best GARCH(p,q) AIC\": r[\"GARCH(p,q) AIC\"],\n",
    "    \"AIC\": r[\"AIC\"],\n",
    "    \"Best GARCH(p,q) BIC\": r[\"GARCH(p,q) BIC\"],\n",
    "    \"BIC\": r[\"BIC\"]\n",
    "} for r in garch_results])\n",
    "\n",
    "print(\"=== GARCH summary results ===\")\n",
    "print(garch_summary_df)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing for GARCH Differences\n",
    "\n",
    "### LR test\n",
    "\n",
    "Given a **GARCH** model for each identified time interval, we then used them in an LR-test to explore differences in volatility structure before and after the events. Specifically, a **GARCH(p, q)** model was fitted on the entire before-and-after sample, serving the role as the restricted model. Then, two sub-models of the same order $(p, q)$ were fitted on their respective time intervals, divided by the event date. These sub-models take on the role as the unrestricted models. \n",
    "\n",
    "The LR test statistic takes the form of:\n",
    "\n",
    "$$\n",
    "LR = -2 \\left( \\ell_{\\text{restricted}} - \\left( \\ell_{\\text{unrestricted}_1} + \\ell_{\\text{unrestricted}_2} \\right) \\right)\n",
    "$$\n",
    "\n",
    "with degrees of freedom:\n",
    "\n",
    "$$\n",
    "df = (k_1 + k_2) - k_r\n",
    "$$\n",
    "\n",
    "However, this test is not strictly speaking formally valid, as a result of the models not being truly nested. As a result, the test distribution under the null is not following a perfect chi-squared distribution. Nonetheless, this procedure can give certain indications of structural breaks.\n",
    "\n",
    "### Wald test\n",
    "\n",
    "To enhance the analysis of the **GARCH** models, we use the **Wald test**. To detect structural breaks in volatility dynamics, we apply the Wald test to compare **GARCH(p, q)** model parameters before and after key financial events. Using the same **GARCH** specification (identified from full-period model selection), we estimate separate models on the pre- and post-event samples.\n",
    "\n",
    "The Wald statistic is computed as:\n",
    "\n",
    "$$\n",
    "W = (\\theta_1 - \\theta_2)^{\\prime} \\left[ \\text{Var}(\\theta_1) + \\text{Var}(\\theta_2) \\right]^{-1} (\\theta_1 - \\theta_2)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\theta_1$ and $\\theta_2$ are the parameter vectors from the pre- and post-event models,\n",
    "- $\\text{Var}(\\theta_1)$ and $\\text{Var}(\\theta_2)$ are their respective covariance matrices.\n",
    "\n",
    "Under the null hypothesis of parameter stability, the test statistic follows a chi-squared distribution with degrees of freedom equal to the number of estimated parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_ratio_test(event_name, full_model, arma_order, garch_order, full_data, break_date):\n",
    "    try:\n",
    "        before_data = full_data.loc[:break_date]\n",
    "        after_data = full_data.loc[break_date:]\n",
    "\n",
    "        arma_before = ARIMA(before_data, order=(arma_order[0], 0, arma_order[1])).fit()\n",
    "        arma_after = ARIMA(after_data, order=(arma_order[0], 0, arma_order[1])).fit()\n",
    "\n",
    "        resid_before = arma_before.resid\n",
    "        resid_after = arma_after.resid\n",
    "\n",
    "        garch_before = arch_model(resid_before, vol=\"Garch\", p=garch_order[0], q=garch_order[1], mean=\"Zero\").fit(disp=\"off\")\n",
    "        garch_after = arch_model(resid_after, vol=\"Garch\", p=garch_order[0], q=garch_order[1], mean=\"Zero\").fit(disp=\"off\")\n",
    "\n",
    "        ll_restricted = full_model.loglikelihood\n",
    "        ll_unrestricted = garch_before.loglikelihood + garch_after.loglikelihood\n",
    "        LR_stat = -2 * (ll_restricted - ll_unrestricted)\n",
    "        df = 3\n",
    "        p_value = 1 - chi2.cdf(LR_stat, df)\n",
    "\n",
    "        return {\n",
    "            \"event\": event_name,\n",
    "            \"ARMA(p,q)\": arma_order,\n",
    "            \"GARCH(p,q)\": garch_order,\n",
    "            \"LR_stat\": LR_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"significant\": \"Yes\" if p_value < 0.05 else \"No\",\n",
    "            \"garch_before\": garch_before,\n",
    "            \"garch_after\": garch_after\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"event\": event_name,\n",
    "            \"error\": str(e)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== DOT_COM_BUBBLE ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "LR statistic: 14.1463, p-value: 0.0027\n",
      "\n",
      "--- GARCH Model (Before Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.001\n",
      "Vol Model:                      GARCH   Log-Likelihood:                2444.27\n",
      "Distribution:                  Normal   AIC:                          -4876.54\n",
      "Method:            Maximum Likelihood   BIC:                          -4848.40\n",
      "                                        No. Observations:                  805\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      805\n",
      "Time:                        13:23:34   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      1.5197e-05  2.657e-11  5.720e+05      0.000 [1.520e-05,1.520e-05]\n",
      "alpha[1]       0.0908      0.130      0.697      0.486     [ -0.164,  0.346]\n",
      "alpha[2]       0.1141  7.870e-02      1.450      0.147  [-4.015e-02,  0.268]\n",
      "beta[1]        0.2060      0.606      0.340      0.734     [ -0.983,  1.394]\n",
      "beta[2]        0.2060      0.700      0.294      0.768     [ -1.165,  1.577]\n",
      "beta[3]        0.2974      0.612      0.486      0.627     [ -0.903,  1.497]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "--- GARCH Model (After Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.001\n",
      "Vol Model:                      GARCH   Log-Likelihood:                2017.21\n",
      "Distribution:                  Normal   AIC:                          -4022.41\n",
      "Method:            Maximum Likelihood   BIC:                          -3995.06\n",
      "                                        No. Observations:                  705\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      705\n",
      "Time:                        13:23:34   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      2.1513e-05  1.221e-06     17.624  1.625e-69 [1.912e-05,2.391e-05]\n",
      "alpha[1]       0.1000  5.039e-02      1.984  4.722e-02   [1.230e-03,  0.199]\n",
      "alpha[2]       0.1000  3.762e-02      2.658  7.859e-03   [2.626e-02,  0.174]\n",
      "beta[1]        0.2333      0.545      0.429      0.668     [ -0.834,  1.301]\n",
      "beta[2]        0.2333      0.890      0.262      0.793     [ -1.511,  1.978]\n",
      "beta[3]        0.2333      0.557      0.419      0.675     [ -0.858,  1.324]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "================== FINANCIAL_CRISIS ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "LR statistic: 10.4966, p-value: 0.0148\n",
      "\n",
      "--- GARCH Model (Before Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.001\n",
      "Vol Model:                      GARCH   Log-Likelihood:                2232.46\n",
      "Distribution:                  Normal   AIC:                          -4454.92\n",
      "Method:            Maximum Likelihood   BIC:                          -4432.31\n",
      "                                        No. Observations:                  680\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      680\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      2.2962e-06  3.766e-10   6097.421      0.000 [2.296e-06,2.297e-06]\n",
      "alpha[1]       0.0324      0.272      0.119      0.905     [ -0.501,  0.565]\n",
      "alpha[2]       0.0324      0.192      0.169      0.866     [ -0.343,  0.408]\n",
      "alpha[3]       0.0324      0.107      0.303      0.762     [ -0.177,  0.242]\n",
      "beta[1]        0.8823  1.412e-02     62.475      0.000     [  0.855,  0.910]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "--- GARCH Model (After Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.002\n",
      "Vol Model:                      GARCH   Log-Likelihood:                1616.63\n",
      "Distribution:                  Normal   AIC:                          -3223.27\n",
      "Method:            Maximum Likelihood   BIC:                          -3201.45\n",
      "                                        No. Observations:                  580\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      580\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      8.0578e-06  3.404e-10  2.367e+04      0.000 [8.057e-06,8.059e-06]\n",
      "alpha[1]       0.0667      0.148      0.449      0.653     [ -0.224,  0.358]\n",
      "alpha[2]       0.0667      0.142      0.468      0.640     [ -0.212,  0.346]\n",
      "alpha[3]       0.0667  6.777e-02      0.984      0.325  [-6.616e-02,  0.199]\n",
      "beta[1]        0.7800  3.697e-02     21.099  8.158e-99     [  0.708,  0.852]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "================== FLASH_CRASH ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "LR statistic: 9.5873, p-value: 0.0224\n",
      "\n",
      "--- GARCH Model (Before Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.002\n",
      "Vol Model:                      GARCH   Log-Likelihood:                1367.77\n",
      "Distribution:                  Normal   AIC:                          -2721.54\n",
      "Method:            Maximum Likelihood   BIC:                          -2691.97\n",
      "                                        No. Observations:                  505\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      505\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      8.9107e-06  2.610e-11  3.415e+05      0.000 [8.911e-06,8.911e-06]\n",
      "alpha[1]       0.0667  6.111e-02      1.091      0.275  [-5.310e-02,  0.186]\n",
      "alpha[2]       0.0667  4.646e-02      1.435      0.151  [-2.439e-02,  0.158]\n",
      "alpha[3]       0.0667  5.499e-02      1.212      0.225  [-4.112e-02,  0.174]\n",
      "beta[1]        0.2600      0.548      0.475      0.635     [ -0.813,  1.333]\n",
      "beta[2]        0.2600      0.643      0.404      0.686     [ -1.001,  1.521]\n",
      "beta[3]        0.2600      0.766      0.340      0.734     [ -1.241,  1.761]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "--- GARCH Model (After Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.002\n",
      "Vol Model:                      GARCH   Log-Likelihood:                1571.53\n",
      "Distribution:                  Normal   AIC:                          -3129.07\n",
      "Method:            Maximum Likelihood   BIC:                          -3099.50\n",
      "                                        No. Observations:                  505\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      505\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      6.9807e-06  4.172e-09   1673.199      0.000 [6.973e-06,6.989e-06]\n",
      "alpha[1]   2.9090e-16  6.404e-02  4.542e-15      1.000     [ -0.126,  0.126]\n",
      "alpha[2]       0.2143  8.017e-02      2.673  7.522e-03   [5.715e-02,  0.371]\n",
      "alpha[3]       0.0486      0.655  7.418e-02      0.941     [ -1.235,  1.332]\n",
      "beta[1]    3.0663e-23      3.733  8.214e-24      1.000     [ -7.316,  7.316]\n",
      "beta[2]        0.3542      1.472      0.241      0.810     [ -2.531,  3.240]\n",
      "beta[3]        0.3290      1.624      0.203      0.839     [ -2.853,  3.511]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "================== COVID_CRASH ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "LR statistic: 19.3544, p-value: 0.0002\n",
      "\n",
      "--- GARCH Model (Before Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.002\n",
      "Vol Model:                      GARCH   Log-Likelihood:                1683.45\n",
      "Distribution:                  Normal   AIC:                          -3358.91\n",
      "Method:            Maximum Likelihood   BIC:                          -3342.02\n",
      "                                        No. Observations:                  504\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      504\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      5.4205e-06  2.325e-10  2.331e+04      0.000 [5.420e-06,5.421e-06]\n",
      "alpha[1]       0.2265  9.223e-02      2.456  1.406e-02   [4.571e-02,  0.407]\n",
      "alpha[2]       0.0293  9.397e-02      0.312      0.755     [ -0.155,  0.213]\n",
      "beta[1]        0.7176  4.911e-02     14.613  2.337e-48     [  0.621,  0.814]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "--- GARCH Model (After Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.002\n",
      "Vol Model:                      GARCH   Log-Likelihood:                1567.82\n",
      "Distribution:                  Normal   AIC:                          -3127.64\n",
      "Method:            Maximum Likelihood   BIC:                          -3110.74\n",
      "                                        No. Observations:                  506\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      506\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      6.2001e-06  3.041e-09   2038.691      0.000 [6.194e-06,6.206e-06]\n",
      "alpha[1]       0.1023  9.841e-02      1.039      0.299  [-9.061e-02,  0.295]\n",
      "alpha[2]       0.0995  7.515e-02      1.325      0.185  [-4.774e-02,  0.247]\n",
      "beta[1]        0.7762  3.665e-02     21.181  1.431e-99     [  0.704,  0.848]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "================== RUSSIA_INVASION ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "LR statistic: 19.8915, p-value: 0.0002\n",
      "\n",
      "--- GARCH Model (Before Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.002\n",
      "Vol Model:                      GARCH   Log-Likelihood:                1554.47\n",
      "Distribution:                  Normal   AIC:                          -3100.94\n",
      "Method:            Maximum Likelihood   BIC:                          -3084.02\n",
      "                                        No. Observations:                  507\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      507\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      4.8804e-06  2.784e-09   1752.840      0.000 [4.875e-06,4.886e-06]\n",
      "alpha[1]       0.2000      0.144      1.388      0.165  [-8.248e-02,  0.482]\n",
      "beta[1]        0.3900      0.208      1.873  6.105e-02  [-1.807e-02,  0.798]\n",
      "beta[2]        0.3900      0.209      1.867  6.190e-02  [-1.942e-02,  0.799]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n",
      "\n",
      "--- GARCH Model (After Event) ---\n",
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:                   None   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.002\n",
      "Vol Model:                      GARCH   Log-Likelihood:                1559.21\n",
      "Distribution:                  Normal   AIC:                          -3110.43\n",
      "Method:            Maximum Likelihood   BIC:                          -3093.55\n",
      "                                        No. Observations:                  502\n",
      "Date:                Tue, Apr 01 2025   Df Residuals:                      502\n",
      "Time:                        13:23:35   Df Model:                            0\n",
      "                              Volatility Model                              \n",
      "============================================================================\n",
      "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
      "----------------------------------------------------------------------------\n",
      "omega      2.8480e-06  2.675e-10  1.064e+04      0.000 [2.847e-06,2.849e-06]\n",
      "alpha[1]       0.1000  2.741e-02      3.649  2.634e-04   [4.629e-02,  0.154]\n",
      "beta[1]        0.4400      0.353      1.245      0.213     [ -0.253,  1.133]\n",
      "beta[2]        0.4400      0.331      1.331      0.183     [ -0.208,  1.088]\n",
      "============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    }
   ],
   "source": [
    "lr_results = []\n",
    "\n",
    "for g in garch_results:\n",
    "    event_name = g[\"event\"]\n",
    "    arma_order = g[\"ARMA(p,q)\"]\n",
    "    garch_order = g[\"GARCH(p,q) AIC\"]\n",
    "    full_model = g[\"model_AIC\"]\n",
    "\n",
    "    period = next(p for p in structured_periods if p[\"event\"] == event_name)\n",
    "    full_data = period[\"returns\"]\n",
    "    break_date = period[\"event_date\"]\n",
    "\n",
    "    result = likelihood_ratio_test(event_name, full_model, arma_order, garch_order, full_data, break_date)\n",
    "    lr_results.append(result)\n",
    "\n",
    "lr_df = pd.DataFrame(lr_results)\n",
    "\n",
    "for result in lr_results:\n",
    "    print(f\"\\n================== {result['event'].upper()} ==================\")\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Significant difference in GARCH parameters? → {result['significant']}\")\n",
    "    print(f\"LR statistic: {result['LR_stat']:.4f}, p-value: {result['p_value']:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- GARCH Model (Before Event) ---\")\n",
    "    print(result[\"garch_before\"].summary())\n",
    "    \n",
    "    print(\"\\n--- GARCH Model (After Event) ---\")\n",
    "    print(result[\"garch_after\"].summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== DOT_COM_BUBBLE ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "Wald statistic: 32.5231, p-value: 1.295036102999525e-05\n",
      "\n",
      "Parameter Differences:\n",
      "omega      -0.000006\n",
      "alpha[1]   -0.009218\n",
      "alpha[2]    0.014101\n",
      "beta[1]    -0.027344\n",
      "beta[2]    -0.027344\n",
      "beta[3]     0.064028\n",
      "Name: params, dtype: float64\n",
      "\n",
      "================== FINANCIAL_CRISIS ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "Wald statistic: 181415896.5412, p-value: 0.0\n",
      "\n",
      "Parameter Differences:\n",
      "omega      -0.000006\n",
      "alpha[1]   -0.034285\n",
      "alpha[2]   -0.034285\n",
      "alpha[3]   -0.034285\n",
      "beta[1]     0.102335\n",
      "Name: params, dtype: float64\n",
      "\n",
      "================== FLASH_CRASH ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "Wald statistic: 9415088.8297, p-value: 0.0\n",
      "\n",
      "Parameter Differences:\n",
      "omega       0.000002\n",
      "alpha[1]    0.066667\n",
      "alpha[2]   -0.147619\n",
      "alpha[3]    0.018105\n",
      "beta[1]     0.260000\n",
      "beta[2]    -0.094245\n",
      "beta[3]    -0.068952\n",
      "Name: params, dtype: float64\n",
      "\n",
      "================== COVID_CRASH ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "Wald statistic: 105076.2831, p-value: 0.0\n",
      "\n",
      "Parameter Differences:\n",
      "omega      -7.795405e-07\n",
      "alpha[1]    1.242027e-01\n",
      "alpha[2]   -7.026394e-02\n",
      "beta[1]    -5.867538e-02\n",
      "Name: params, dtype: float64\n",
      "\n",
      "================== RUSSIA_INVASION ==================\n",
      "Significant difference in GARCH parameters? → Yes\n",
      "Wald statistic: 43024809.2626, p-value: 0.0\n",
      "\n",
      "Parameter Differences:\n",
      "omega       0.000002\n",
      "alpha[1]    0.100000\n",
      "beta[1]    -0.050000\n",
      "beta[2]    -0.050000\n",
      "Name: params, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from arch import arch_model\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def garch_wald_test(garch_before, garch_after):\n",
    "    b1 = garch_before.params\n",
    "    b2 = garch_after.params\n",
    "    V1 = garch_before.param_cov\n",
    "    V2 = garch_after.param_cov\n",
    "\n",
    "\n",
    "    diff = b1 - b2\n",
    "    V = V1 + V2\n",
    "    W = diff.values.T @ np.linalg.inv(V.values) @ diff.values\n",
    "    df = len(diff)\n",
    "    p = 1 - chi2.cdf(W, df)\n",
    "\n",
    "    return {\n",
    "        \"Wald_stat\": W,\n",
    "        \"df\": df,\n",
    "        \"p_value\": p,\n",
    "        \"significant\": p < 0.05,\n",
    "        \"param_diff\": diff\n",
    "    }\n",
    "wald_results = []\n",
    "\n",
    "for g in garch_results:\n",
    "    event_name = g[\"event\"]\n",
    "    garch_order = g[\"GARCH(p,q) AIC\"]\n",
    "    arma_order = g[\"ARMA(p,q)\"]\n",
    "\n",
    "    if garch_order is None or arma_order is None:\n",
    "        continue\n",
    "\n",
    "    period = next(p for p in structured_periods if p[\"event\"] == event_name)\n",
    "    full_data = period[\"returns\"]\n",
    "    before_data = full_data.loc[:period[\"event_date\"]]\n",
    "    after_data = full_data.loc[period[\"event_date\"]:]\n",
    "\n",
    "\n",
    "    try:\n",
    "        arma_before = ARIMA(before_data, order=(arma_order[0], 0, arma_order[1])).fit()\n",
    "        arma_after = ARIMA(after_data, order=(arma_order[0], 0, arma_order[1])).fit()\n",
    "\n",
    "        resid_before = arma_before.resid\n",
    "        resid_after = arma_after.resid\n",
    "\n",
    "        garch_before = arch_model(resid_before, vol=\"Garch\", p=garch_order[0], q=garch_order[1], mean=\"Zero\").fit(disp=\"off\")\n",
    "        garch_after = arch_model(resid_after, vol=\"Garch\", p=garch_order[0], q=garch_order[1], mean=\"Zero\").fit(disp=\"off\")\n",
    "\n",
    "        wald_result = garch_wald_test(garch_before, garch_after)\n",
    "\n",
    "        wald_results.append({\n",
    "            \"event\": event_name,\n",
    "            \"ARMA(p,q)\": arma_order,\n",
    "            \"GARCH(p,q)\": garch_order,\n",
    "            **wald_result\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        wald_results.append({\n",
    "            \"event\": event_name,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "\n",
    "wald_df = pd.DataFrame(wald_results)\n",
    "\n",
    "for result in wald_results:\n",
    "    print(f\"\\n================== {result['event'].upper()} ==================\")\n",
    "\n",
    "    if 'error' in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Significant difference in GARCH parameters? → {'Yes' if result['significant'] else 'No'}\")\n",
    "    print(f\"Wald statistic: {result['Wald_stat']:.4f}, p-value: {result['p_value']}\")\n",
    "    print(\"\\nParameter Differences:\")\n",
    "    print(result[\"param_diff\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 ADF\n",
    "\n",
    "- **ADF Statistic:** -22.5054  \n",
    "- **p-value:** 0.0000  \n",
    "- **Number of Lags Used:** 48  \n",
    "- **Number of Observations:** 24,377  \n",
    "\n",
    "The low p-value indicates that the return series is likely stationary. \n",
    "\n",
    "### 3.3.2 F-test sample variance\n",
    "| Event             | F-stat   | p-value        |\n",
    "|------------------|----------|----------------|\n",
    "| dot_com_bubble   | 0.677315 | 9.206945e-08   |\n",
    "| financial_crisis | 0.241116 | 9.501963e-68   |\n",
    "| flash_crash      | 2.797905 | 2.220446e-16   |\n",
    "| covid_crash      | 0.468542 | 4.473343e-17   |\n",
    "| russia_invasion  | 1.959486 | 8.215650e-14   |\n",
    "\n",
    "Table 1: Low p-values indicates that the overall level of variance is different in sub-periods for each event window.\n",
    "\n",
    "### 3.3.3 ARCH-LM \n",
    "\n",
    "| Event             | p | q | LM_stat     | p_value        | ARCH_effects |\n",
    "|------------------|---|---|-------------|----------------|---------------|\n",
    "| dot_com_bubble   | 0 | 0 | 106.888422  | 2.259278e-18   | Yes           |\n",
    "| financial_crisis | 3 | 0 | 398.177955  | 2.298807e-79   | Yes           |\n",
    "| flash_crash      | 2 | 0 | 293.699580  | 3.335327e-57   | Yes           |\n",
    "| covid_crash      | 3 | 2 | 334.970642  | 6.140149e-66   | Yes           |\n",
    "| russia_invasion  | 0 | 3 | 305.627744  | 1.003831e-59   | Yes           |\n",
    "\n",
    "Table 2: p-values indicate that there is a clear presence of ARCH effects in the return series.\n",
    "\n",
    "### 3.3.4 Chow test\n",
    "\n",
    "| Event             | Model Order | F-stat     | p-value        | Significant |\n",
    "|------------------|-------------|------------|----------------|-------------|\n",
    "| dot_com_bubble   | (0, 0)      | 4.281926   | 3.868969e-02   | Yes         |\n",
    "| financial_crisis | (3, 0)      | 0.000000   | 1.000000e+00   | No          |\n",
    "| flash_crash      | (2, 0)      | 2.000858   | 1.122111e-01   | No          |\n",
    "| covid_crash      | (3, 2)      | 0.000000   | 1.000000e+00   | No          |\n",
    "| russia_invasion  | (0, 3)      | 8.839006   | 5.153350e-07   | Yes         |\n",
    "\n",
    "Table 3: Chow test indicate mixed results in regards to whether the results are significant or not. However, for the cases of the \"financial crisis\" and \"covid crash\", we suspect an issue, like numerical instability or something similar, due to the result of test statistic = 0. This can also be a result of the Chow test not being guaranteed F-distributed under the assumptions of time series analysis, as it typically is used for regular linear regression models where the residuals are assumed iid. \n",
    "\n",
    "### 3.3.5 GARCH fit\n",
    "\n",
    "| Event             | ARMA(p,q) | Best GARCH(p,q) AIC | AIC           | Best GARCH(p,q) BIC | BIC           |\n",
    "|------------------|-----------|----------------------|---------------|----------------------|---------------|\n",
    "| dot_com_bubble   | (0, 0)    | (2, 3)               | -8896.810455  | (1, 1)               | -8871.086035  |\n",
    "| financial_crisis | (3, 0)    | (3, 1)               | -7677.692660  | (3, 1)               | -7652.002295  |\n",
    "| flash_crash      | (2, 0)    | (3, 3)               | -5855.022640  | (2, 1)               | -5828.006177  |\n",
    "| covid_crash      | (3, 2)    | (2, 1)               | -6475.197944  | (1, 1)               | -6458.179392  |\n",
    "| russia_invasion  | (0, 3)    | (1, 2)               | -6199.471489  | (1, 2)               | -6179.808595  |\n",
    "\n",
    "Table 4: Best fitting GARCH models, based on their repsective ARMA models, according to AIC and BIC informaiton criterion. \n",
    "\n",
    "### 3.3.6 LR test\n",
    "| Event             | p-value  | LR Test Statistic |\n",
    "|------------------|----------|-------------------|\n",
    "| Dot com          | 0.0027   | 14.1463           |\n",
    "| Financial crisis | 0.0148   | 10.4966           |\n",
    "| Flash crash      | 0.0224   | 9.5873            |\n",
    "| Covid-19         | 0.0002   | 19.3544           |\n",
    "| Russia invasion  | 0.0002   | 19.8915           |\n",
    "\n",
    "Table 5: LR test results on GARCH models. p-values are generally low, indicating rejection of the null hypothesis. The \"flash crash\" and \"financial crisis\" are not rejected under the 1% rejection rule, and these results are therefore less strong than the other events.\n",
    "\n",
    "### 3.3.7 Wald test\n",
    "\n",
    "| Event             | Wald Statistic     | p-value             |\n",
    "|------------------|--------------------|---------------------|\n",
    "| dot_com_bubble   | 32.5231            | 1.295036e-05        |\n",
    "| financial_crisis | 181415896.5412     | 0.0                 |\n",
    "| flash_crash      | 9415088.8297       | 0.0                 |\n",
    "| covid_crash      | 105076.2831        | 0.0                 |\n",
    "| russia_invasion  | 43024809.2626      | 0.0                 |\n",
    "\n",
    "Table 6: Wald test results. P-values are strongly saying that the parameters are different for the various sub-periods for all events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
